# prettier-ignore
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-advisor-service
  namespace: {{ .Values.namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-advisor-service
  template:
    metadata:
      labels:
        app: ai-advisor-service
        component: backend
        monitoring: "true"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9082"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      imagePullSecrets:
        - name: ghcr
      containers:
        - name: ai-advisor-service
          image: "{{ .Values.aiAdvisorService.image.repository }}:{{ .Values.aiAdvisorService.image.tag }}"
          imagePullPolicy: Always
          ports:
            - containerPort: 8082
              name: http
            - containerPort: 9082
              name: management
          env:
            # - name: OPENAI_API_KEY
            #   valueFrom:
            #     secretKeyRef:
            #       name: tum-study-planner-secrets
            #       key: OPENAI_API_KEY
            - name: JWT_SECRET
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: JWT_SECRET
            - name: LLM_INFERENCE_SERVICE_URL
              value: "http://llm-inference-service.{{ .Values.namespace }}.svc.cluster.local:{{ .Values.services.llmInferenceService.port }}"
            - name: llm.inference.service.url
              value: "http://llm-inference-service.{{ .Values.namespace }}.svc.cluster.local:{{ .Values.services.llmInferenceService.port }}"
          resources:
            requests:
              cpu: {{ .Values.resources.aiAdvisorService.requests.cpu }}
              memory: {{ .Values.resources.aiAdvisorService.requests.memory }}
            limits:
              cpu: {{ .Values.resources.aiAdvisorService.limits.cpu }}
              memory: {{ .Values.resources.aiAdvisorService.limits.memory }}
