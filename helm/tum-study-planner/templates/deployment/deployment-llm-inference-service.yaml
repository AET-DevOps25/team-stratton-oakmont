# prettier-ignore
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-inference-service
  namespace: {{ .Values.namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-inference-service
  template:
    metadata:
      labels:
        app: llm-inference-service
    spec:
      imagePullSecrets:
        - name: ghcr
      containers:
        - name: llm-inference-service
          image: "{{ .Values.llmInferenceService.image.repository }}:{{ .Values.llmInferenceService.image.tag }}"
          ports:
            - containerPort: 8084
          env:
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: OPENAI_API_KEY
            # Explicitly set OpenAI API type to prevent Google auto-detection
            - name: OPENAI_API_TYPE
              value: "openai"
            # Disable Google API auto-detection completely
            - name: GOOGLE_API_KEY
              value: ""
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: ""
            - name: GOOGLE_CLOUD_PROJECT
              value: ""
            - name: GCLOUD_PROJECT
              value: ""
            - name: WEAVIATE_HOST
              value: {{ .Values.llmInferenceService.env.WEAVIATE_HOST | quote }}
            - name: WEAVIATE_PORT
              value: {{ .Values.llmInferenceService.env.WEAVIATE_PORT | quote }}
            - name: WEAVIATE_GRPC_PORT
              value: {{ .Values.llmInferenceService.env.WEAVIATE_GRPC_PORT | quote }}
            - name: WEAVIATE_URL
              value: {{ .Values.llmInferenceService.env.WEAVIATE_URL | quote }}
            - name: WEAVIATE_GRPC_URL
              value: {{ .Values.llmInferenceService.env.WEAVIATE_GRPC_URL | quote }}
            - name: OPENAI_BASE_URL
              value: {{ .Values.llmInferenceService.env.OPENAI_BASE_URL | quote }}
            - name: OLLAMA_BASE_URL
              value: {{ .Values.llmInferenceService.env.OLLAMA_BASE_URL | quote }}
            - name: CHAT_MODEL
              value: {{ .Values.llmInferenceService.env.CHAT_MODEL | quote }}
            - name: EMBEDDING_MODEL
              value: {{ .Values.llmInferenceService.env.EMBEDDING_MODEL | quote }}
            - name: STUDY_DATA_DB_HOST
              value: {{ .Values.llmInferenceService.env.STUDY_DATA_DB_HOST | quote }}
            - name: STUDY_DATA_DB_PORT
              value: {{ .Values.llmInferenceService.env.STUDY_DATA_DB_PORT | quote }}
            - name: STUDY_DATA_DB_NAME
              value: {{ .Values.llmInferenceService.env.STUDY_DATA_DB_NAME | quote }}
            - name: STUDY_DATA_DB_USER
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: STUDY_DATA_DB_USER
            - name: STUDY_DATA_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: STUDY_DATA_DB_PASSWORD
            - name: STUDY_PLAN_DB_HOST
              value: {{ .Values.llmInferenceService.env.STUDY_PLAN_DB_HOST | quote }}
            - name: STUDY_PLAN_DB_PORT
              value: {{ .Values.llmInferenceService.env.STUDY_PLAN_DB_PORT | quote }}
            - name: STUDY_PLAN_DB_NAME
              value: {{ .Values.llmInferenceService.env.STUDY_PLAN_DB_NAME | quote }}
            - name: STUDY_PLAN_DB_USER
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: STUDY_PLAN_DB_USER
            - name: STUDY_PLAN_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: tum-study-planner-secrets
                  key: STUDY_PLAN_DB_PASSWORD
          resources:
            requests:
              cpu: {{ .Values.resources.llmInferenceService.requests.cpu }}
              memory: {{ .Values.resources.llmInferenceService.requests.memory }}
            limits:
              cpu: {{ .Values.resources.llmInferenceService.limits.cpu }}
              memory: {{ .Values.resources.llmInferenceService.limits.memory }}
          volumeMounts:
            - name: course-data
              mountPath: /app/data
      volumes:
        - name: course-data
          emptyDir: {}
